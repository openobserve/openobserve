name: Playwright UI Tests

on:
  push:
    branches:
      - "main"
    # paths-ignore:
    #   - "**.md"
    #   - "**.yml"
    #   - "**.yaml"
  pull_request:
    branches:
      - "*"
    # paths-ignore:
    #   - "**.md"
    #   - "**.yml"
    #   - "**.yaml"

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

env:
  COLUMNS: 150
  ZO_ROOT_USER_EMAIL: root@example.com
  ZO_ROOT_USER_PASSWORD: Complexpass#123
  ZO_BASE_URL: http://localhost:5080
  WS_ZO_BASE_URL: ws://localhost:5080
  ZO_BASE_URL_SC: http://localhost:5080
  ZO_BASE_URL_SC_UI: http://localhost:5080
  INGESTION_URL: http://localhost:5080
  ORGNAME: default
  ZO_QUICK_MODE_NUM_FIELDS: 100
  ZO_QUICK_MODE_STRATEGY: first
  ZO_ALLOW_USER_DEFINED_SCHEMAS: true
  ZO_INGEST_ALLOWED_UPTO: 5
  ZO_FEATURE_QUERY_EXCLUDE_ALL: false
  ZO_USAGE_BATCH_SIZE: 200
  ZO_USAGE_PUBLISH_INTERVAL: 2
  ZO_USAGE_REPORTING_ENABLED: true
  ZO_MIN_AUTO_REFRESH_INTERVAL: 5
  ZO_STREAMING_ENABLED: true
  ZO_COLS_PER_RECORD_LIMIT: "80000"
  ZO_SMTP_ENABLED: true
  ZO_FORMAT_STREAM_NAME_TO_LOWERCASE: false
  ZO_CREATE_ORG_THROUGH_INGESTION: true
  ZO_UTF8_VIEW_ENABLED: false
  UPLOAD_TO_TESTDINO: ${{ vars.UPLOAD_TO_TESTDINO || 'false' }}

jobs:
  build_binary:
    name: build_binary
    runs-on:
      labels: repo-openobserve-standard-16

    steps:
      - name: Remove unused tools
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /opt/ghc
          sudo rm -rf "/usr/local/share/boost"
          sudo rm -rf "$AGENT_TOOLSDIRECTORY"

      - name: Clone the current repo
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Setup Rust Toolchain
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: nightly-2025-07-20
          targets: x86_64-unknown-linux-gnu
      - uses: Swatinem/rust-cache@v2
        with:
          cache-on-failure: true
          prefix-key: playwright
      - name: Install Protoc
        uses: arduino/setup-protoc@v3
        with:
          version: "21.12"
      - uses: actions/setup-node@v5
        with:
          node-version: 22

      - name: Build frontend code
        env:
          NODE_OPTIONS: "--max-old-space-size=8192"
          VITE_COVERAGE: "true"
          COVERAGE: "true"
        run: cd web && npm install && npm run build

      - name: Build and run binary
        run: cargo build --release --target x86_64-unknown-linux-gnu

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: release-binary
          path: target/x86_64-unknown-linux-gnu/release/openobserve
          retention-days: 1

  ui_integration_tests:
    name: e2e / ${{ matrix.testfolder }}
    needs: [build_binary]
    runs-on:
      labels: repo-openobserve-standard-8
    # container:
    #   image: mcr.microsoft.com/playwright:v1.50.0-jammy
    #   options: --user root
    strategy:
      matrix:
        include:
          - testfolder: "GeneralTests"
            browser: "chrome"
            run_files:
              [
                "sanity.spec.js",
                "changeOrg.spec.js",
                "enrichment.spec.js",
                "schema.spec.js",
                "schemaload.spec.js",
                "serviceAccount.spec.js",
                "usersOrg.spec.js",
                "org.spec.js",
              ]
          - testfolder: "Logs-Core"
            browser: "chrome"
            run_files:
              [
                "join.spec.js",
                "logshistogram.spec.js",
                "logspage.spec.js",
                "logsquickmode.spec.js",
                "pagination.spec.js",
                "unflattened.spec.js",
                "logstable.spec.js",
              ]
          - testfolder: "Logs-Queries"
            browser: "chrome"
            run_files:
              [
                "logsDownloads.spec.js",
                "logsqueries.spec.js",
                "secondsPrecisionAdded.spec.js",
                "logsqueries.cte.spec.js",
                "logsqueries.matchall.spec.js",
                "searchpartition.spec.js",
              ]
          - testfolder: "Alerts"
            browser: "chrome"
            run_files:
              [
                "alerts-e2e-flow.spec.js",
                "alerts-ui-operations.spec.js",
                "alerts-import.spec.js",
              ]
          - testfolder: "Dashboards-Core"
            browser: "chrome"
            run_files:
              [
                "dashboard.spec.js",
                "dashboard2.spec.js",
                "dashboardtype.spec.js",
                "dashboard-folder.spec.js",
                "dashboard-import.spec.js",
                "maxquery.spec.js",
              ]
          - testfolder: "Dashboards-Settings"
            browser: "chrome"
            run_files:
              [
                "dashboard-filter.spec.js",
                "dashboard-general-setting.spec.js",
                "dashboard-tabs-setting.spec.js",
                "dashboard-variables-setting.spec.js",
                "dashboard-transpose.spec.js",
              ]
          - testfolder: "Dashboards-Charts"
            browser: "chrome"
            run_files: [
                "custom-charts.spec.js",
                "dashboard-geoMap.spec.js",
                "dashboard-maps.spec.js",
                "dashboard-multi-y-axis.spec.js",
                "dashboard-html-chart.spec.js",
                "visualize.spec.js",
                # "visualization-vrl.spec.js"
              ]
          - testfolder: "Dashboards-Streaming"
            browser: "chrome"
            run_files: ["dashboard-streaming.spec.js",]
          - testfolder: "Pipelines"
            browser: "chrome"
            run_files: [
                "pipelines.spec.js",
                "pipeline-dynamic.spec.js",
                "pipeline-core.spec.js",
                # "remotepipeline.spec.js"
              ]
          - testfolder: "Reports"
            browser: "chrome"
            run_files: [
              "reportsScheduleNow.spec.js", 
              "reportsScheduleLater.spec.js"
              ]
          - testfolder: "Streams"
            browser: "chrome"
            run_files:
              [
                "multiselect-stream.spec.js",
                "streamname.spec.js",
                "streaming.spec.js",
              ]
    steps:
      - name: Clone the current repo
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Download artifacts
        uses: actions/download-artifact@v5
        with:
          name: release-binary
          path: release-binary

      - name: Start OpenObserve
        run: chmod +x ./release-binary/openobserve && ./release-binary/openobserve > o2.log 2>&1 &

      - name: Wait for start
        run: sleep 60

      - name: Ensure we are getting a reply from the server
        run: curl http://localhost:5080/web/login

      - name: Create coverage json folder
        run: mkdir -p tests/ui-testing/.nyc_output

      - uses: actions/setup-node@v5
        with:
          node-version: 22

      - name: Check if this is a rerun
        id: check_rerun
        run: |
          echo "::notice::GitHub run attempt: ${{ github.run_attempt }}"
          if [ "${{ github.run_attempt }}" -gt "1" ]; then
            echo "is_rerun=true" >> $GITHUB_OUTPUT
            echo "::notice::This is a rerun (attempt ${{ github.run_attempt }}). Will attempt to run only failed tests."
          else
            echo "is_rerun=false" >> $GITHUB_OUTPUT
            echo "::notice::This is the first run. Will run all tests in matrix."
          fi

      - name: Install dependencies and run ui-tests
        env:
          TESTDINO_TOKEN: ${{ secrets.TESTDINO_API_TOKEN }}
          GH_TOKEN: ${{ github.token }}
        run: |
          touch .env
          echo "ZO_ROOT_USER_EMAIL=${ZO_ROOT_USER_EMAIL}" >> .env
          echo "ZO_ROOT_USER_PASSWORD=${ZO_ROOT_USER_PASSWORD}" >> .env
          echo "ZO_BASE_URL=${ZO_BASE_URL}" >> .env
          echo "WS_ZO_BASE_URL=${WS_ZO_BASE_URL}" >> .env
          echo "ZO_BASE_URL_SC=${ZO_BASE_URL_SC}" >> .env
          echo "ZO_BASE_URL_SC_UI=${ZO_BASE_URL_SC_UI}" >> .env
          echo "INGESTION_URL=${INGESTION_URL}" >> .env
          echo "ORGNAME=${ORGNAME}" >> .env
          echo "ZO_SMTP_ENABLED=${ZO_SMTP_ENABLED}" >> .env
          mv .env tests/ui-testing
          cd tests/ui-testing && npm ci
          npx playwright install --with-deps chromium

          # Check if this is a rerun
          IS_RERUN="${{ steps.check_rerun.outputs.is_rerun }}"

          if [ "$IS_RERUN" = "true" ]; then
            echo "::group::Fetching last failed tests from TestDino"
            # Use custom cache ID that includes run_id to distinguish separate workflow runs
            # Format: gh_openobserve_main_12345678 (for main) or gh_openobserve_feature-branch_12345678 (for PRs)
            CACHE_ID="gh_openobserve_${{ github.ref_name }}_${{ github.run_id }}"
            echo "::notice::Using cache ID: $CACHE_ID"
            # Try to get last failed tests from TestDino
            # Redirect stderr to /dev/null to avoid capturing npm warnings
            # Filter out TestDino debug output (lines starting with ===, DEBUG:, or spaces)
            if RAW_OUTPUT="$(npx tdpw last-failed --cache-id "$CACHE_ID" 2>/dev/null)"; then
              # Filter debug lines and get the actual test path
              # Remove debug output, empty lines, and metadata lines
              LAST_FAILED_FLAGS="$(echo "$RAW_OUTPUT" | \
                grep -v '^===' | \
                grep -v '^DEBUG:' | \
                grep -v '^   ' | \
                grep -v '^$' | \
                grep -v 'üîç' | \
                grep -v 'üìÅ' | \
                grep -v 'üìã' | \
                grep -v '‚ö†Ô∏è' | \
                grep -v 'üèóÔ∏è' | \
                grep -v 'üì§' | \
                grep -v '‚úÖ' | \
                grep -v '‚úì' | \
                tail -1)"
              # Trim whitespace
              LAST_FAILED_FLAGS="$(echo "$LAST_FAILED_FLAGS" | xargs)"

              echo "DEBUG: Raw TestDino output length: ${#RAW_OUTPUT} chars"
              echo "DEBUG: Filtered output: '$LAST_FAILED_FLAGS'"
              echo "DEBUG: Filtered output length: ${#LAST_FAILED_FLAGS} chars"

              # Check if we got a valid test path (should contain .spec.js)
              if [ -n "$LAST_FAILED_FLAGS" ] && echo "$LAST_FAILED_FLAGS" | grep -q '\.spec\.js'; then
                echo "::notice::‚úÖ Found failed tests from previous run."
                echo "::notice::TestDino flags: $LAST_FAILED_FLAGS"
                RERUN_MODE="optimized"
                EXTRA_PW_FLAGS="$LAST_FAILED_FLAGS"
              else
                echo "::warning::TestDino returned no failed tests. Falling back to running all tests in this matrix job."
                echo "::warning::This means you'll be billed for all tests. Please investigate why last-failed returned empty."
                RERUN_MODE="fallback"
                EXTRA_PW_FLAGS=""
              fi
            else
              echo "::error::Failed to fetch last failed tests from TestDino (exit code: $?)."
              echo "::warning::Falling back to running all tests in this matrix job."
              echo "::warning::This means you'll be billed for all tests. Please check TestDino integration."
              RERUN_MODE="fallback"
              EXTRA_PW_FLAGS=""
            fi
            echo "::endgroup::"
          else
            RERUN_MODE="normal"
            EXTRA_PW_FLAGS=""
          fi

          # Get list of files to run using join function
          FILE_LIST="${{ join(matrix.run_files, ' ') }}"
          echo "DEBUG: FILE_LIST = $FILE_LIST"
          echo "DEBUG: matrix.testfolder = ${{ matrix.testfolder }}"

          if [ -n "$FILE_LIST" ]; then
            # Map logical folder names to actual directories
            case "${{ matrix.testfolder }}" in
              "Logs-Core"|"Logs-Queries")
                ACTUAL_FOLDER="Logs"
                ;;
              "Dashboards-Core"|"Dashboards-Settings"|"Dashboards-Charts"|"Dashboards-Streaming")
                ACTUAL_FOLDER="Dashboards"
                ;;
              *)
                ACTUAL_FOLDER="${{ matrix.testfolder }}"
                ;;
            esac

            echo "DEBUG: ACTUAL_FOLDER = $ACTUAL_FOLDER"

            # Build file paths
            FILE_PATHS=""
            for file in $FILE_LIST; do
              FILE_PATH="./playwright-tests/$ACTUAL_FOLDER/$file"
              echo "DEBUG: Will run file: $FILE_PATH"
              FILE_PATHS="$FILE_PATHS $FILE_PATH"
            done

            # Determine what to run based on rerun mode
            if [ "$RERUN_MODE" = "optimized" ]; then
              # TestDino returns ALL failed tests from the previous run
              # Format examples:
              # Single: "SDR/test.spec.js -g test name"
              # Multiple: "Logs/test1.spec.js -g name1 Pipelines/test2.spec.js -g name2"

              echo "DEBUG: Full TestDino output (all failed tests): $EXTRA_PW_FLAGS"
              echo "DEBUG: Current shard folder: $ACTUAL_FOLDER"

              # Strategy: Extract only tests that start with "$ACTUAL_FOLDER/"
              # Use grep to find lines matching our shard folder
              SHARD_TESTS=""

              # Check if the TestDino output contains tests for this shard
              # Look for pattern: $ACTUAL_FOLDER/something.spec.js
              if echo "$EXTRA_PW_FLAGS" | grep -q "$ACTUAL_FOLDER/.*\.spec\.js"; then
                echo "DEBUG: Found test(s) for this shard in TestDino output"

                # IMPORTANT: Based on observation, TestDino returns ONE test at a time
                # Format: "Folder/file.spec.js -g test name"
                # Simply check if it starts with our folder and pass it through

                # Extract file path (everything before -g or end of string)
                TEST_FILE=$(echo "$EXTRA_PW_FLAGS" | grep -oE "$ACTUAL_FOLDER/[^ ]+\.spec\.js" | head -1)

                if [ -n "$TEST_FILE" ]; then
                  # Check if file actually starts with our folder (double-check)
                  if [[ "$TEST_FILE" == "$ACTUAL_FOLDER/"* ]]; then
                    # Parse out the file path and test name separately for proper quoting
                    # Extract file path (before -g)
                    TEST_FILE_PATH=$(echo "$EXTRA_PW_FLAGS" | sed "s/ -g.*//" | sed "s|^|./playwright-tests/|")

                    # Check if there's a -g flag
                    if echo "$EXTRA_PW_FLAGS" | grep -q " -g "; then
                      # Extract test name (after -g)
                      TEST_NAME=$(echo "$EXTRA_PW_FLAGS" | sed 's/.*-g //')

                      echo "DEBUG: File path: $TEST_FILE_PATH"
                      echo "DEBUG: Test name: $TEST_NAME"
                      echo "::notice::üéØ OPTIMIZED RERUN: Running failed test from this shard"
                      echo "DEBUG: Final command: npx playwright test \"$TEST_FILE_PATH\" -g \"$TEST_NAME\""

                      # Properly quote the test name to handle spaces and special chars
                      npx playwright test "$TEST_FILE_PATH" -g "$TEST_NAME"
                    else
                      # No -g flag, just run the file
                      echo "DEBUG: File path: $TEST_FILE_PATH (no -g flag)"
                      echo "::notice::üéØ OPTIMIZED RERUN: Running failed test file from this shard"
                      echo "DEBUG: Final command: npx playwright test \"$TEST_FILE_PATH\""

                      npx playwright test "$TEST_FILE_PATH"
                    fi
                  else
                    echo "::notice::‚è≠Ô∏è Test file doesn't match shard folder exactly. Skipping."
                    exit 0
                  fi
                else
                  echo "::warning::Failed to extract test file path. Falling back to skip."
                  exit 0
                fi
              else
                echo "::notice::‚è≠Ô∏è OPTIMIZED RERUN: No failed tests found for '$ACTUAL_FOLDER' shard in TestDino output"
                echo "::notice::Checking if this shard was cancelled/abruptly ended in previous attempt..."

                # Check the status of this matrix job in the previous attempt
                # Rule: If shard was cancelled/abruptly ended ‚Üí treat as failed ‚Üí run full test suite
                PREV_ATTEMPT=$((${{ github.run_attempt }} - 1))

                if [ "$PREV_ATTEMPT" -ge 1 ]; then
                  # Job name format: "e2e / {matrix.testfolder}"
                  JOB_NAME="e2e / ${{ matrix.testfolder }}"

                  echo "DEBUG: Checking previous attempt #$PREV_ATTEMPT for job: $JOB_NAME"

                  # Use GitHub REST API to get job status from specific attempt
                  # This is guaranteed to work and provides attempt-specific data
                  API_RESPONSE=$(curl -s -H "Authorization: token $GH_TOKEN" \
                    -H "Accept: application/vnd.github.v3+json" \
                    "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/attempts/$PREV_ATTEMPT/jobs" 2>/dev/null)

                  if [ $? -eq 0 ] && [ -n "$API_RESPONSE" ]; then
                    # Successfully got API response, parse it
                    PREV_JOB_STATUS=$(echo "$API_RESPONSE" | jq -r ".jobs[] | select(.name == \"$JOB_NAME\") | .conclusion" 2>/dev/null)

                    echo "DEBUG: Previous job status: $PREV_JOB_STATUS"

                    if [ "$PREV_JOB_STATUS" = "cancelled" ] || [ "$PREV_JOB_STATUS" = "null" ] || [ -z "$PREV_JOB_STATUS" ]; then
                      echo "::warning::‚ö†Ô∏è Previous shard was cancelled/abruptly ended (status: ${PREV_JOB_STATUS:-not found})"
                      echo "::warning::Treating as FAILED - running FULL test suite for this shard"
                      echo "DEBUG: Running all matrix tests: npx playwright test $FILE_PATHS"
                      npx playwright test $FILE_PATHS
                    elif [ "$PREV_JOB_STATUS" = "success" ]; then
                      echo "::notice::‚úÖ Previous shard completed successfully - all tests passed"
                      echo "::notice::No failed tests to rerun. Exiting successfully."
                      exit 0
                    elif [ "$PREV_JOB_STATUS" = "failure" ]; then
                      echo "::warning::‚ö†Ô∏è Previous shard failed but TestDino has no failures recorded"
                      echo "::warning::This shouldn't happen - running FULL test suite for safety"
                      echo "DEBUG: Running all matrix tests: npx playwright test $FILE_PATHS"
                      npx playwright test $FILE_PATHS
                    else
                      echo "::warning::‚ö†Ô∏è Unknown job status: $PREV_JOB_STATUS"
                      echo "::warning::Running FULL test suite for safety"
                      echo "DEBUG: Running all matrix tests: npx playwright test $FILE_PATHS"
                      npx playwright test $FILE_PATHS
                    fi
                  else
                    echo "::error::Failed to fetch job status from GitHub API"
                    echo "::warning::Falling back to running FULL test suite for safety"
                    echo "DEBUG: Running all matrix tests: npx playwright test $FILE_PATHS"
                    npx playwright test $FILE_PATHS
                  fi
                else
                  echo "::notice::‚úÖ This is the first run, no previous attempt to check"
                  echo "::notice::No failed tests to rerun. Exiting successfully."
                  exit 0
                fi
              fi
            else
              # Normal run or fallback
              if [ "$RERUN_MODE" = "fallback" ]; then
                echo "::warning::‚ö†Ô∏è FALLBACK RERUN: Running all tests in matrix (TestDino optimization failed)"
              fi
              echo "DEBUG: Final command: npx playwright test $FILE_PATHS"
              npx playwright test $FILE_PATHS
            fi
          else
            echo "No files specified to run for ${{ matrix.testfolder }} folder"
          fi 

      - name: Sanitize Test Folder Name
        shell: bash
        run: |
          # Assign the matrix variable to a Bash variable
          SANITIZED_FOLDERNAME="${{ matrix.testfolder }}"
          # Export as a GitHub Actions environment variable
          echo "SANITIZED_FOLDERNAME=$SANITIZED_FOLDERNAME" >> $GITHUB_ENV

      - name: Upload Coverage Data
        uses: actions/upload-artifact@v4
        with:
          name: playwright-coverage-${{ env.SANITIZED_FOLDERNAME }}-attempt-${{ github.run_attempt }}
          path: tests/ui-testing/.nyc_output
          include-hidden-files: true

      - name: Generate Coverage Report
        run: cd tests/ui-testing && npx nyc report

      - name: Upload blob report to GitHub Actions Artifacts
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: blob-report-${{ matrix.testfolder }}-attempt-${{ github.run_attempt }}
          path: tests/ui-testing/blob-report
          retention-days: 1

      - name: Check OpenObserve logs
        if: always()
        run: cat o2.log

  merge_and_upload_reports:
    name: Merge Reports and Upload to TestDino
    needs: [ui_integration_tests]
    if: ${{ !cancelled() && needs.ui_integration_tests.result != 'skipped' }}
    runs-on:
      labels: repo-openobserve-standard-8

    steps:
      - name: Clone the current repo
        uses: actions/checkout@v5

      - name: Setup Node.js
        uses: actions/setup-node@v5
        with:
          node-version: '22'

      - name: Install project dependencies
        run: cd tests/ui-testing && npm ci

      - name: Clean up cancelled shard artifacts from previous attempts
        if: ${{ github.run_attempt > 1 }}
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          echo "::group::Cleaning up cancelled shard artifacts"
          echo "::notice::[TESTDINO_RERUN_OPT] üîç Starting cleanup step for attempt #${{ github.run_attempt }}"
          echo "::notice::[TESTDINO_RERUN_OPT] Current workflow run ID: ${{ github.run_id }}"
          echo "::notice::[TESTDINO_RERUN_OPT] Current repository: ${{ github.repository }}"

          # Check previous attempt (Attempt N-1)
          PREV_ATTEMPT=$((${{ github.run_attempt }} - 1))
          echo "::notice::[TESTDINO_RERUN_OPT] üîé Checking attempt #$PREV_ATTEMPT for cancelled shards..."

          # Get all matrix jobs from previous attempt
          echo "::notice::[TESTDINO_RERUN_OPT] üì° Calling GitHub API to fetch jobs from attempt #$PREV_ATTEMPT..."
          API_RESPONSE=$(curl -s -H "Authorization: token $GH_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/attempts/$PREV_ATTEMPT/jobs")

          echo "::notice::[TESTDINO_RERUN_OPT] üì¶ API Response received (length: ${#API_RESPONSE} chars)"
          echo "::debug::[TESTDINO_RERUN_OPT] Full API response: $API_RESPONSE"

          # Extract job names and their conclusions
          # Job name format: "e2e / {testfolder}"
          echo "::notice::[TESTDINO_RERUN_OPT] üîç Extracting cancelled shards from API response..."
          CANCELLED_SHARDS=$(echo "$API_RESPONSE" | jq -r '.jobs[] | select(.name | startswith("e2e / ")) | select(.conclusion == "cancelled" or .conclusion == null or .conclusion == "") | .name' | sed 's/e2e \/ //')

          echo "::notice::[TESTDINO_RERUN_OPT] üìã Cancelled shards detected: ${CANCELLED_SHARDS:-<none>}"

          if [ -z "$CANCELLED_SHARDS" ]; then
            echo "::notice::[TESTDINO_RERUN_OPT] ‚úÖ No cancelled shards found in attempt #$PREV_ATTEMPT"
            echo "::notice::[TESTDINO_RERUN_OPT] All shards from previous attempt completed successfully or failed cleanly"
          else
            echo "::warning::[TESTDINO_RERUN_OPT] ‚ö†Ô∏è Found cancelled shards in attempt #$PREV_ATTEMPT:"
            echo "[TESTDINO_RERUN_OPT] Cancelled shard list:"
            echo "$CANCELLED_SHARDS" | while read shard; do
              echo "  - $shard"
            done

            # Fetch all artifacts for this run first
            echo "::notice::[TESTDINO_RERUN_OPT] üì° Fetching all artifacts for run ${{ github.run_id }}..."
            ALL_ARTIFACTS=$(curl -s -H "Authorization: token $GH_TOKEN" \
              -H "Accept: application/vnd.github.v3+json" \
              "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts")

            echo "::notice::[TESTDINO_RERUN_OPT] üì¶ Total artifacts found: $(echo "$ALL_ARTIFACTS" | jq '.total_count')"
            echo "::debug::[TESTDINO_RERUN_OPT] Artifact list: $(echo "$ALL_ARTIFACTS" | jq -r '.artifacts[].name')"

            # Delete artifacts for cancelled shards
            DELETED_COUNT=0
            SKIPPED_COUNT=0

            for shard in $CANCELLED_SHARDS; do
              ARTIFACT_NAME="blob-report-${shard}-attempt-${PREV_ATTEMPT}"
              echo "::warning::[TESTDINO_RERUN_OPT] üóëÔ∏è Processing deletion for artifact: $ARTIFACT_NAME"

              # Get artifact ID
              ARTIFACT_ID=$(echo "$ALL_ARTIFACTS" | jq -r ".artifacts[] | select(.name == \"$ARTIFACT_NAME\") | .id")

              if [ -n "$ARTIFACT_ID" ] && [ "$ARTIFACT_ID" != "null" ]; then
                echo "::warning::[TESTDINO_RERUN_OPT] üîç Found artifact ID: $ARTIFACT_ID for $ARTIFACT_NAME"
                echo "::warning::[TESTDINO_RERUN_OPT] üóëÔ∏è Deleting artifact via GitHub API..."

                # Delete the artifact
                DELETE_RESPONSE=$(curl -X DELETE -s -w "\n%{http_code}" -H "Authorization: token $GH_TOKEN" \
                  -H "Accept: application/vnd.github.v3+json" \
                  "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$ARTIFACT_ID")

                HTTP_CODE=$(echo "$DELETE_RESPONSE" | tail -1)
                echo "::notice::[TESTDINO_RERUN_OPT] Delete API response code: $HTTP_CODE"

                if [ "$HTTP_CODE" = "204" ]; then
                  echo "::notice::[TESTDINO_RERUN_OPT] ‚úÖ Successfully deleted artifact: $ARTIFACT_NAME (ID: $ARTIFACT_ID)"
                  DELETED_COUNT=$((DELETED_COUNT + 1))
                else
                  echo "::error::[TESTDINO_RERUN_OPT] ‚ùå Failed to delete artifact: $ARTIFACT_NAME (HTTP: $HTTP_CODE)"
                fi
              else
                echo "::notice::[TESTDINO_RERUN_OPT] ‚è≠Ô∏è Artifact not found: $ARTIFACT_NAME"
                echo "::notice::[TESTDINO_RERUN_OPT] Reason: May have already been deleted, never uploaded, or cancelled before blob upload step"
                SKIPPED_COUNT=$((SKIPPED_COUNT + 1))
              fi
            done

            echo "::notice::[TESTDINO_RERUN_OPT] üìä Deletion Summary:"
            echo "::notice::[TESTDINO_RERUN_OPT]   - Artifacts deleted: $DELETED_COUNT"
            echo "::notice::[TESTDINO_RERUN_OPT]   - Artifacts skipped (not found): $SKIPPED_COUNT"
          fi
          echo "::notice::[TESTDINO_RERUN_OPT] ‚úÖ Cleanup step completed"
          echo "::endgroup::"

      - name: Download blob reports from current attempt
        uses: actions/download-artifact@v4
        with:
          path: tests/ui-testing/all-blob-reports
          pattern: blob-report-*-attempt-${{ github.run_attempt }}
          merge-multiple: true

      - name: List downloaded artifacts from current attempt
        run: |
          echo "::notice::[TESTDINO_RERUN_OPT] üìÇ Listing artifacts downloaded from attempt #${{ github.run_attempt }}:"
          ls -lah tests/ui-testing/all-blob-reports/
          echo "::notice::[TESTDINO_RERUN_OPT] Total blob files in current attempt:"
          find tests/ui-testing/all-blob-reports/ -name "*.zip" | wc -l
          echo "::notice::[TESTDINO_RERUN_OPT] Blob file list:"
          find tests/ui-testing/all-blob-reports/ -name "*.zip" -exec basename {} \;

      - name: Download successful shard reports from previous attempts (if rerun)
        if: ${{ github.run_attempt > 1 }}
        run: |
          echo "::group::[TESTDINO_RERUN_OPT] Downloading successful shards from ALL previous attempts"
          CURRENT_ATTEMPT=${{ github.run_attempt }}
          echo "::notice::[TESTDINO_RERUN_OPT] üì• Current attempt: #$CURRENT_ATTEMPT"
          echo "::notice::[TESTDINO_RERUN_OPT] Will download artifacts from attempts 1 to $((CURRENT_ATTEMPT - 1))"

          # Download using actions/download-artifact would require dynamic pattern
          # Instead, we'll use GitHub API to download specific artifacts
          cd tests/ui-testing

          # Get all artifacts for this workflow run
          echo "::notice::[TESTDINO_RERUN_OPT] üì° Fetching artifact list from GitHub API..."
          ARTIFACTS=$(curl -s -H "Authorization: token ${{ github.token }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts")

          echo "::notice::[TESTDINO_RERUN_OPT] üì¶ Total artifacts in workflow run: $(echo "$ARTIFACTS" | jq '.total_count')"

          # Filter artifacts from ALL previous attempts (those that survived cleanup)
          # This includes attempt-1, attempt-2, ..., attempt-(N-1)
          echo "::notice::[TESTDINO_RERUN_OPT] üîç Filtering blob artifacts from previous attempts..."
          PREV_ATTEMPT_ARTIFACTS=$(echo "$ARTIFACTS" | jq -r ".artifacts[] | select(.name | startswith(\"blob-report-\")) | select(.name | contains(\"attempt-\")) | select(.name | test(\"attempt-$CURRENT_ATTEMPT\") | not) | .name")

          echo "::notice::[TESTDINO_RERUN_OPT] üìã All previous attempt artifacts (after cleanup):"
          if [ -z "$PREV_ATTEMPT_ARTIFACTS" ]; then
            echo "::notice::[TESTDINO_RERUN_OPT] ‚ÑπÔ∏è No artifacts found from previous attempts"
            echo "::notice::[TESTDINO_RERUN_OPT] This is expected if all shards ran in current attempt"
          else
            echo "$PREV_ATTEMPT_ARTIFACTS" | while read artifact_name; do
              echo "  - $artifact_name"
            done

            DOWNLOAD_COUNT=0
            DOWNLOAD_FAIL_COUNT=0

            echo "$PREV_ATTEMPT_ARTIFACTS" | while read artifact_name; do
              echo "::notice::[TESTDINO_RERUN_OPT] üì• Processing artifact: $artifact_name"

              # Get download URL
              ARTIFACT_ID=$(echo "$ARTIFACTS" | jq -r ".artifacts[] | select(.name == \"$artifact_name\") | .id")

              if [ -n "$ARTIFACT_ID" ] && [ "$ARTIFACT_ID" != "null" ]; then
                echo "::notice::[TESTDINO_RERUN_OPT] üîó Artifact ID: $ARTIFACT_ID"
                echo "::notice::[TESTDINO_RERUN_OPT] üì• Downloading via GitHub API..."

                # Download and extract artifact
                HTTP_CODE=$(curl -L -w "%{http_code}" -H "Authorization: token ${{ github.token }}" \
                  -H "Accept: application/vnd.github+json" \
                  "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$ARTIFACT_ID/zip" \
                  -o "all-blob-reports/${artifact_name}.zip")

                if [ "$HTTP_CODE" = "200" ]; then
                  echo "::notice::[TESTDINO_RERUN_OPT] ‚úÖ Download successful (HTTP 200)"
                  echo "::notice::[TESTDINO_RERUN_OPT] üì¶ Extracting artifact..."

                  # Extract
                  cd all-blob-reports
                  unzip -q "${artifact_name}.zip" -d temp_extract 2>&1 | head -5

                  # Count extracted files
                  EXTRACTED_FILES=$(find temp_extract -name "*.zip" | wc -l)
                  echo "::notice::[TESTDINO_RERUN_OPT] üìä Extracted $EXTRACTED_FILES blob files"

                  # Move extracted blob files to main directory
                  find temp_extract -name "*.zip" -exec mv {} . \;
                  rm -rf temp_extract "${artifact_name}.zip"
                  cd ..

                  echo "::notice::[TESTDINO_RERUN_OPT] ‚úÖ Successfully processed $artifact_name"
                  DOWNLOAD_COUNT=$((DOWNLOAD_COUNT + 1))
                else
                  echo "::error::[TESTDINO_RERUN_OPT] ‚ùå Download failed with HTTP code: $HTTP_CODE"
                  DOWNLOAD_FAIL_COUNT=$((DOWNLOAD_FAIL_COUNT + 1))
                fi
              else
                echo "::error::[TESTDINO_RERUN_OPT] ‚ùå Could not get artifact ID for $artifact_name"
                DOWNLOAD_FAIL_COUNT=$((DOWNLOAD_FAIL_COUNT + 1))
              fi
            done

            echo "::notice::[TESTDINO_RERUN_OPT] üìä Download Summary:"
            echo "::notice::[TESTDINO_RERUN_OPT]   - Successfully downloaded: $DOWNLOAD_COUNT"
            echo "::notice::[TESTDINO_RERUN_OPT]   - Failed downloads: $DOWNLOAD_FAIL_COUNT"
          fi
          echo "::notice::[TESTDINO_RERUN_OPT] ‚úÖ Previous attempt download step completed"
          echo "::endgroup::"
        continue-on-error: true

      - name: List all blob reports before merge
        run: |
          echo "::notice::[TESTDINO_RERUN_OPT] üìÇ Final blob report directory contents before merge:"
          ls -lah tests/ui-testing/all-blob-reports/
          echo "::notice::[TESTDINO_RERUN_OPT] üìä Total blob files to merge:"
          find tests/ui-testing/all-blob-reports/ -name "*.zip" | wc -l
          echo "::notice::[TESTDINO_RERUN_OPT] üìã Complete blob file list:"
          find tests/ui-testing/all-blob-reports/ -name "*.zip" -exec basename {} \; | sort

      - name: Merge Reports
        run: |
          cd tests/ui-testing

          echo "::notice::[TESTDINO_RERUN_OPT] üîÄ Starting merge-reports process..."
          echo "::notice::[TESTDINO_RERUN_OPT] Current attempt: #${{ github.run_attempt }}"

          # Unset CI to use non-CI reporter config (html + json instead of blob)
          unset CI
          echo "::notice::[TESTDINO_RERUN_OPT] Running: npx playwright merge-reports --config playwright.config.js ./all-blob-reports"
          npx playwright merge-reports --config playwright.config.js ./all-blob-reports

          echo "::notice::[TESTDINO_RERUN_OPT] ‚úÖ Merge completed successfully"
          echo "::notice::[TESTDINO_RERUN_OPT] üìÇ Contents of playwright-results:"
          ls -la playwright-results/
          echo "::notice::[TESTDINO_RERUN_OPT] üìÇ Contents of html-report:"
          ls -la playwright-results/html-report/
          echo "::notice::[TESTDINO_RERUN_OPT] üìÑ Checking report.json:"
          ls -lh playwright-results/report.json

          # Parse report.json to show test counts
          echo "::notice::[TESTDINO_RERUN_OPT] üìä Analyzing merged report.json..."
          if [ -f "playwright-results/report.json" ]; then
            TOTAL_TESTS=$(jq '[.suites[].specs[]] | length' playwright-results/report.json 2>/dev/null || echo "0")
            PASSED_TESTS=$(jq '[.suites[].specs[].tests[].results[] | select(.status == "passed")] | length' playwright-results/report.json 2>/dev/null || echo "0")
            FAILED_TESTS=$(jq '[.suites[].specs[].tests[].results[] | select(.status == "failed")] | length' playwright-results/report.json 2>/dev/null || echo "0")
            SKIPPED_TESTS=$(jq '[.suites[].specs[].tests[].results[] | select(.status == "skipped")] | length' playwright-results/report.json 2>/dev/null || echo "0")

            echo "::notice::[TESTDINO_RERUN_OPT] üìä Test Results Summary:"
            echo "::notice::[TESTDINO_RERUN_OPT]   - Total test specs: $TOTAL_TESTS"
            echo "::notice::[TESTDINO_RERUN_OPT]   - Passed: $PASSED_TESTS"
            echo "::notice::[TESTDINO_RERUN_OPT]   - Failed: $FAILED_TESTS"
            echo "::notice::[TESTDINO_RERUN_OPT]   - Skipped: $SKIPPED_TESTS"
            echo "::notice::[TESTDINO_RERUN_OPT]   - Total executions: $(($PASSED_TESTS + $FAILED_TESTS + $SKIPPED_TESTS))"
          else
            echo "::error::[TESTDINO_RERUN_OPT] ‚ùå report.json not found!"
          fi

      - name: Cache test failures to TestDino
        if: always()
        env:
          TESTDINO_TOKEN: ${{ secrets.TESTDINO_API_TOKEN }}
        run: |
          cd tests/ui-testing
          echo "::group::Caching test failure metadata to TestDino"
          if [ -f "playwright-results/report.json" ]; then
            echo "::notice::JSON report found at playwright-results/report.json"
            ls -lh playwright-results/report.json
            # tdpw cache expects to be run from the directory containing report.json
            # Change to playwright-results directory where report.json lives
            cd playwright-results
            # Use custom cache ID that includes run_id to distinguish separate workflow runs
            # Format: gh_openobserve_main_12345678 (for main) or gh_openobserve_feature-branch_12345678 (for PRs)
            CACHE_ID="gh_openobserve_${{ github.ref_name }}_${{ github.run_id }}"
            echo "::notice::Using cache ID: $CACHE_ID"
            if npx tdpw cache --cache-id "$CACHE_ID"; then
              echo "::notice::‚úÖ Successfully cached test failure metadata to TestDino cloud"
              echo "::notice::This data will be used for optimized reruns if tests fail"
            else
              echo "::warning::‚ö†Ô∏è Failed to cache test metadata to TestDino"
              echo "::warning::Rerun optimization may not work properly"
            fi
          else
            echo "::error::JSON report not found at playwright-results/report.json"
            echo "::warning::Cannot cache test failures - skipping"
          fi
          echo "::endgroup::"

      - name: Upload to TestDino
        if: ${{ (success() || failure()) && env.UPLOAD_TO_TESTDINO == 'true' }}
        run: |
          cd tests/ui-testing
          npx --yes tdpw upload playwright-results \
            --json-report playwright-results/report.json \
            --html-report playwright-results/html-report \
            --upload-html \
            --token="${{ secrets.TESTDINO_API_TOKEN }}"

  generate_coverage_report:
    name: Generate Coverage Report
    needs: [build_binary, ui_integration_tests]
    runs-on: repo-openobserve-standard-8
    if: success() || failure()

    steps:
      - name: Clone the current repo
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Download Playwright Coverage Data
        uses: actions/download-artifact@v5
        with:
          pattern: playwright-coverage-*-attempt-${{ github.run_attempt }}
          path: merged-coverage
          merge-multiple: true

      - name: Verify Downloaded Files
        run: ls -R merged-coverage # Check the structure and contents

      - name: Move Coverage Files to .nyc_output
        run: |
          mkdir -p tests/ui-testing/.nyc_output
          mv merged-coverage/* tests/ui-testing/.nyc_output/ || echo "No files to move"

      - name: Generate Coverage Report
        run: cd tests/ui-testing && npm ci && npx nyc report

      - name: Upload Coverage Report
        uses: actions/upload-artifact@v4
        if: hashFiles('tests/ui-testing/coverage-report/**') != ''
        with:
          name: coverage-report
          path: tests/ui-testing/coverage-report
          retention-days: 7

  playwright_summary:
    runs-on:
      labels: repo-openobserve-standard-8
    permissions: {}
    needs: [build_binary, ui_integration_tests, merge_and_upload_reports, generate_coverage_report]
    if: always()
    steps:
      - name: Check test results
        run: |
          # Check all job results - accept success or skipped for all jobs
          BUILD_OK=false
          UI_OK=false
          MERGE_OK=false
          COV_OK=false

          if [ "${{ needs.build_binary.result }}" == "success" ] || [ "${{ needs.build_binary.result }}" == "skipped" ]; then
            BUILD_OK=true
          fi

          if [ "${{ needs.ui_integration_tests.result }}" == "success" ] || [ "${{ needs.ui_integration_tests.result }}" == "skipped" ]; then
            UI_OK=true
          fi

          if [ "${{ needs.merge_and_upload_reports.result }}" == "success" ] || [ "${{ needs.merge_and_upload_reports.result }}" == "skipped" ]; then
            MERGE_OK=true
          fi

          if [ "${{ needs.generate_coverage_report.result }}" == "success" ] || [ "${{ needs.generate_coverage_report.result }}" == "skipped" ]; then
            COV_OK=true
          fi

          if [ "$BUILD_OK" == "true" ] && [ "$UI_OK" == "true" ] && [ "$MERGE_OK" == "true" ] && [ "$COV_OK" == "true" ]; then
            echo "All Playwright tests completed successfully"
            exit 0
          else
            echo "Playwright tests failed:"
            echo "  build_binary: ${{ needs.build_binary.result }}"
            echo "  ui_integration_tests: ${{ needs.ui_integration_tests.result }}"
            echo "  merge_and_upload_reports: ${{ needs.merge_and_upload_reports.result }}"
            echo "  generate_coverage_report: ${{ needs.generate_coverage_report.result }}"
            exit 1
          fi
